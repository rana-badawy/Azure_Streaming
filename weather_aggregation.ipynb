{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\r\n",
        "from pyspark.sql.types import *"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "streamingpool",
              "statement_id": 3,
              "statement_ids": [
                3
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": null,
              "session_id": "1",
              "normalized_state": "finished",
              "queued_time": "2024-12-10T20:55:27.6472513Z",
              "session_start_time": null,
              "execution_start_time": "2024-12-10T20:55:27.8113664Z",
              "execution_finish_time": "2024-12-10T20:55:27.9718088Z",
              "parent_msg_id": "728c9fe6-e96c-4202-836e-e7e04abbc1ff"
            },
            "text/plain": "StatementMeta(streamingpool, 1, 3, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gold_schema = StructType([\r\n",
        "    StructField(\"temperature\", IntegerType()),\r\n",
        "    StructField(\"humidity\", IntegerType()),\r\n",
        "    StructField(\"city\", StringType()),\r\n",
        "    StructField(\"timestamp\", TimestampType()),\r\n",
        "    StructField(\"date\", DateType()),\r\n",
        "    StructField(\"hour\", IntegerType())\r\n",
        "])"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "streamingpool",
              "statement_id": 4,
              "statement_ids": [
                4
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": null,
              "session_id": "1",
              "normalized_state": "finished",
              "queued_time": "2024-12-10T20:55:30.6146094Z",
              "session_start_time": null,
              "execution_start_time": "2024-12-10T20:55:30.7456778Z",
              "execution_finish_time": "2024-12-10T20:55:30.9049483Z",
              "parent_msg_id": "b40d1abe-81f9-40b0-8019-4130326cea3a"
            },
            "text/plain": "StatementMeta(streamingpool, 1, 4, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weather_df = (spark.readStream\r\n",
        "    .format(\"delta\")\r\n",
        "    .load(\"abfss://gold@streamingsa.dfs.core.windows.net/EventHub/weather\")\r\n",
        ")\r\n",
        "\r\n",
        "aggregated_df = weather_df.groupBy(\"city\", \"date\", \"hour\").agg(\r\n",
        "    {\"temperature\": \"mean\",\r\n",
        "    \"humidity\": \"mean\"}\r\n",
        "    )\r\n",
        "\r\n",
        "(aggregated_df.writeStream\r\n",
        "    .option(\"checkpointLocation\", \"abfss://checkpoint@streamingsa.dfs.core.windows.net/checkpoint3\")\r\n",
        "    .outputMode(\"complete\")\r\n",
        "    .format(\"delta\")\r\n",
        "    .option(\"path\", \"abfss://gold@streamingsa.dfs.core.windows.net/weather_aggregated\")\r\n",
        "    .start()\r\n",
        ")\r\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "streamingpool",
              "statement_id": 7,
              "statement_ids": [
                7
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": null,
              "session_id": "1",
              "normalized_state": "finished",
              "queued_time": "2024-12-10T20:59:35.2095827Z",
              "session_start_time": null,
              "execution_start_time": "2024-12-10T20:59:35.4074596Z",
              "execution_finish_time": "2024-12-10T20:59:36.5274033Z",
              "parent_msg_id": "8930592d-cd11-4527-8113-ee7231228a4f"
            },
            "text/plain": "StatementMeta(streamingpool, 1, 7, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "<pyspark.sql.streaming.query.StreamingQuery at 0x7c81276425f0>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}